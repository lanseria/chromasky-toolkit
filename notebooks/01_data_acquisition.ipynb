{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bc0cf6",
   "metadata": {},
   "source": [
    "# 第 1 步: 获取过去指定数据（使用 https://cds.climate.copernicus.eu/api 数据源）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13648db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Config: 未找到 .env 文件于 /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/.env\n",
      "\n",
      "--- 使用的配置 ---\n",
      "CDS API Key Loaded: Yes\n",
      "Extraction Area (North): 54.0\n",
      "Data Directory: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data\n",
      "Target Date for this run: 2025-07-18\n"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "import logging\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, date\n",
    "from zoneinfo import ZoneInfo\n",
    "from typing import Dict, Set, List\n",
    "import zipfile\n",
    "\n",
    "# --- 1. 从我们的配置文件中导入所有常量 ---\n",
    "# 因为项目是以可编辑模式安装的 (-e .), 我们可以直接从包中导入\n",
    "from chromasky_toolkit import config\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. 定义本次运行的特定参数 ---\n",
    "# 注意：像目标日期这样的变量不适合放在 config.py 中，因为它每次运行都可能不同。\n",
    "# 把它留在 Notebook 中是正确的做法。\n",
    "TARGET_DATE_STR = \"2025-07-18\" \n",
    "\n",
    "# --- 3. 设置日志 (这部分也可以保留在 Notebook 中) ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"ERA5_Downloader\")\n",
    "\n",
    "# --- 4. 验证导入的配置 (可选) ---\n",
    "print(\"\\n--- 使用的配置 ---\")\n",
    "print(f\"CDS API Key Loaded: {'Yes' if config.CDS_API_KEY else 'No'}\")\n",
    "print(f\"Extraction Area (North): {config.AREA_EXTRACTION['north']}\")\n",
    "print(f\"Data Directory: {config.DATA_DIR}\")\n",
    "print(f\"Target Date for this run: {TARGET_DATE_STR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9345fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_utc_dates_and_hours(target_local_date: date) -> Dict[str, Set[int]]:\n",
    "    \"\"\"\n",
    "    根据目标本地日期和预设的日出/日落时间，计算出需要下载的UTC日期和小时。\n",
    "    这是处理跨时区、跨零点问题的关键。\n",
    "    \"\"\"\n",
    "    local_tz = ZoneInfo(config.LOCAL_TZ)\n",
    "    all_event_times = config.SUNRISE_EVENT_TIMES + config.SUNSET_EVENT_TIMES\n",
    "    utc_date_hours: Dict[str, Set[int]] = {}\n",
    "\n",
    "    logger.info(f\"为本地日期 {target_local_date} 计算所需的 UTC 时间...\")\n",
    "    for time_str in all_event_times:\n",
    "        try:\n",
    "            local_dt = datetime.combine(target_local_date, datetime.strptime(time_str, '%H:%M').time(), tzinfo=local_tz)\n",
    "            utc_dt = local_dt.astimezone(timezone.utc)\n",
    "            \n",
    "            utc_date_str = utc_dt.strftime('%Y-%m-%d')\n",
    "            if utc_date_str not in utc_date_hours:\n",
    "                utc_date_hours[utc_date_str] = set()\n",
    "            utc_date_hours[utc_date_str].add(utc_dt.hour)\n",
    "            # logger.debug(f\"本地时间 {local_dt} -> UTC 时间 {utc_dt}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"处理时间 '{time_str}' 时出错: {e}\")\n",
    "\n",
    "    logger.info(f\"计算完成的 UTC 请求信息: {utc_date_hours}\")\n",
    "    return utc_date_hours\n",
    "\n",
    "\n",
    "def download_era5_data(target_local_date: date):\n",
    "    \"\"\"\n",
    "    为指定的本地日期下载 ERA5 再分析数据。\n",
    "    *** 新版本：增加了自动解压 ZIP 文件的功能 ***\n",
    "    \"\"\"\n",
    "    if not (config.CDS_API_KEY):\n",
    "        logger.error(\"❌ CDS API 配置未找到，无法继续下载。\")\n",
    "        return None\n",
    "\n",
    "    output_dir = config.ERA5_DATA_DIR / target_local_date.strftime('%Y-%m-%d')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    final_output_file = output_dir / \"era5_data.nc\"\n",
    "    \n",
    "    # 定义一个临时的下载文件名\n",
    "    temp_download_path = output_dir / \"temp_download\"\n",
    "\n",
    "    logger.info(f\"--- [ERA5] 函数内部检查路径: {final_output_file} ---\")\n",
    "    \n",
    "    if final_output_file.exists():\n",
    "        logger.info(f\"✅ (函数内部) 最终文件 '{final_output_file.name}' 已存在，跳过。\")\n",
    "        return final_output_file\n",
    "\n",
    "    required_utc_info = get_required_utc_dates_and_hours(target_local_date)\n",
    "    if not required_utc_info:\n",
    "        logger.warning(\"未能计算出任何需要下载的UTC日期和小时。\")\n",
    "        return None\n",
    "\n",
    "    years, months, days, hours = set(), set(), set(), set()\n",
    "    for utc_date_str, hours_set in required_utc_info.items():\n",
    "        dt_obj = datetime.strptime(utc_date_str, '%Y-%m-%d')\n",
    "        years.add(f\"{dt_obj.year}\")\n",
    "        months.add(f\"{dt_obj.month:02d}\")\n",
    "        days.add(f\"{dt_obj.day:02d}\")\n",
    "        hours.update([f\"{h:02d}:00\" for h in hours_set])\n",
    "    \n",
    "    request_params = {\n",
    "        'year': sorted(list(years)),\n",
    "        'month': sorted(list(months)),\n",
    "        'day': sorted(list(days)),\n",
    "        'time': sorted(list(hours)),\n",
    "    }\n",
    "    \n",
    "    logger.info(\"将为以下参数发起下载请求:\")\n",
    "    for key, value in request_params.items():\n",
    "        logger.info(f\"  > {key.capitalize()}: {value}\")\n",
    "\n",
    "    c = cdsapi.Client(timeout=600, quiet=False, url=\"https://cds.climate.copernicus.eu/api\", key=config.CDS_API_KEY)\n",
    "    area_bounds = [config.AREA_EXTRACTION[k] for k in [\"north\", \"west\", \"south\", \"east\"]]\n",
    "    logger.info(f\"请求区域边界: {area_bounds}\")\n",
    "    try:\n",
    "        # 1. 下载到临时的文件，而不是直接命名为 .nc\n",
    "        logger.info(\"正在向 CDS 服务器发送请求...\")\n",
    "        c.retrieve(\n",
    "            'reanalysis-era5-single-levels',\n",
    "            {\n",
    "                'product_type': 'reanalysis',\n",
    "                'format': 'netcdf', # 即使请求 netcdf, 服务器也可能返回 zip\n",
    "                'variable': [\n",
    "                    \"high_cloud_cover\", \"medium_cloud_cover\", \"low_cloud_cover\", \n",
    "                    \"total_cloud_cover\", \"total_precipitation\", \"surface_pressure\",\n",
    "                    \"2m_temperature\", \"2m_dewpoint_temperature\"\n",
    "                ],\n",
    "                'area': area_bounds,\n",
    "                **request_params\n",
    "            },\n",
    "            str(temp_download_path)\n",
    "        )\n",
    "        logger.info(f\"✅ 临时文件已成功下载到: {temp_download_path}\")\n",
    "\n",
    "        # 2. 检查下载的是 ZIP 还是直接就是 NC\n",
    "        if zipfile.is_zipfile(temp_download_path):\n",
    "            logger.info(\"检测到下载文件为 ZIP 压缩包，开始解压...\")\n",
    "            with zipfile.ZipFile(temp_download_path, 'r') as zip_ref:\n",
    "                # 寻找解压出来的 .nc 文件\n",
    "                nc_files_in_zip = [f for f in zip_ref.namelist() if f.endswith('.nc')]\n",
    "                if not nc_files_in_zip:\n",
    "                    raise FileNotFoundError(\"ZIP 包中未找到任何 .nc 文件！\")\n",
    "                \n",
    "                # 解压第一个找到的 .nc 文件\n",
    "                source_nc_path = zip_ref.extract(nc_files_in_zip[0], path=output_dir)\n",
    "                logger.info(f\"已解压出 NetCDF 文件: {source_nc_path}\")\n",
    "                \n",
    "                # 将解压出的文件重命名为我们最终想要的名字\n",
    "                Path(source_nc_path).rename(final_output_file)\n",
    "                logger.info(f\"已将文件重命名为: {final_output_file}\")\n",
    "        else:\n",
    "            # 如果不是 ZIP，说明直接下载的就是 NetCDF 文件\n",
    "            logger.info(\"检测到下载文件为 NetCDF，直接重命名。\")\n",
    "            temp_download_path.rename(final_output_file)\n",
    "\n",
    "        return final_output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ 下载或解压过程中发生严重错误: {e}\", exc_info=True)\n",
    "        return None\n",
    "    finally:\n",
    "        # 4. 清理临时文件\n",
    "        if temp_download_path.exists():\n",
    "            temp_download_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c91c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_analysis_report(ds: xr.Dataset) -> str:\n",
    "    \"\"\"\n",
    "    根据 xarray.Dataset 对象，生成一份详细的 Markdown 格式的分析报告。\n",
    "\n",
    "    Args:\n",
    "        ds: 已打开的 xarray Dataset 对象。\n",
    "\n",
    "    Returns:\n",
    "        一个包含完整报告的 Markdown 格式字符串。\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    source_file = Path(ds.encoding.get(\"source\", \"N/A\")).name\n",
    "    \n",
    "    report_lines.append(f\"# NetCDF 文件分析报告: `{source_file}`\")\n",
    "    report_lines.append(f\"报告生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # 1. 全局属性\n",
    "    report_lines.append(\"\\n## 1. 全局属性 (Global Attributes)\")\n",
    "    if ds.attrs:\n",
    "        for key, value in ds.attrs.items():\n",
    "            report_lines.append(f\"- **{key}:** `{value}`\")\n",
    "    else:\n",
    "        report_lines.append(\"- (无全局属性)\")\n",
    "\n",
    "    # 2. 维度信息\n",
    "    report_lines.append(\"\\n## 2. 维度信息 (Dimensions)\")\n",
    "    for dim_name, dim_size in ds.sizes.items():\n",
    "        report_lines.append(f\"- `{dim_name}`: **{dim_size}**\")\n",
    "\n",
    "    # 3. 坐标变量\n",
    "    report_lines.append(\"\\n## 3. 坐标变量 (Coordinates)\")\n",
    "    for coord_name in ds.coords:\n",
    "        coord_var = ds[coord_name]\n",
    "        report_lines.append(f\"\\n### 坐标: `{coord_name}`\")\n",
    "        report_lines.append(f\"- **维度:** `{coord_var.dims}`\")\n",
    "        report_lines.append(f\"- **类型:** `{coord_var.dtype}`\")\n",
    "        if 'units' in coord_var.attrs:\n",
    "            report_lines.append(f\"- **单位:** {coord_var.attrs.get('long_name', '')} (`{coord_var.attrs.get('units', '')}`)\")\n",
    "        if 'time' in coord_name:\n",
    "            report_lines.append(f\"- **时间范围 (UTC):** `{coord_var.min().values}` 到 `{coord_var.max().values}`\")\n",
    "        elif 'lat' in coord_name or 'lon' in coord_name:\n",
    "            report_lines.append(f\"- **范围:** `{coord_var.min().values:.2f}` 到 `{coord_var.max().values:.2f}`\")\n",
    "\n",
    "    # 4. 数据变量\n",
    "    report_lines.append(\"\\n## 4. 数据变量 (Data Variables)\")\n",
    "    for var_name in ds.data_vars:\n",
    "        var = ds[var_name]\n",
    "        report_lines.append(f\"\\n### 变量: `{var_name}`\")\n",
    "        report_lines.append(f\"- **维度 (shape):** `{var.dims}` -> `{var.shape}`\")\n",
    "        report_lines.append(f\"- **数据类型:** `{var.dtype}`\")\n",
    "        if var.attrs:\n",
    "            report_lines.append(\"- **属性:**\")\n",
    "            for attr_key, attr_value in var.attrs.items():\n",
    "                report_lines.append(f\"  - **{attr_key}:** `{attr_value}`\")\n",
    "        if var.ndim > 0:\n",
    "            indexers = {dim: 0 for dim in var.dims}\n",
    "            sample_value = var.isel(**indexers).values\n",
    "            report_lines.append(f\"- **抽样值 (在索引 {indexers}):** `{sample_value:.4f}`\")\n",
    "            \n",
    "    return \"\\n\".join(report_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2676ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 14:25:37,735 - INFO - ===== 开始处理本地日期: 2025-07-18 =====\n",
      "2025-08-07 14:25:37,736 - INFO - NC 文件不存在，开始执行下载流程...\n",
      "2025-08-07 14:25:37,736 - INFO - --- [ERA5] 函数内部检查路径: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data/raw/era5/2025-07-18/era5_data.nc ---\n",
      "2025-08-07 14:25:37,737 - INFO - 为本地日期 2025-07-18 计算所需的 UTC 时间...\n",
      "2025-08-07 14:25:37,737 - INFO - 计算完成的 UTC 请求信息: {'2025-07-17': {20, 21, 22, 23}, '2025-07-18': {0, 10, 11, 12, 13}}\n",
      "2025-08-07 14:25:37,738 - INFO - 将为以下参数发起下载请求:\n",
      "2025-08-07 14:25:37,738 - INFO -   > Year: ['2025']\n",
      "2025-08-07 14:25:37,738 - INFO -   > Month: ['07']\n",
      "2025-08-07 14:25:37,738 - INFO -   > Day: ['17', '18']\n",
      "2025-08-07 14:25:37,739 - INFO -   > Time: ['00:00', '10:00', '11:00', '12:00', '13:00', '20:00', '21:00', '22:00', '23:00']\n",
      "2025-08-07 14:25:38,669 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-08-07 14:25:38,669 - INFO - [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-08-07 14:25:38,670 - INFO - 请求区域边界: [54.0, 70.0, 0.0, 135.0]\n",
      "2025-08-07 14:25:38,670 - INFO - 正在向 CDS 服务器发送请求...\n",
      "2025-08-07 14:25:39,702 INFO Request ID is 615085a6-a8b7-4bd8-8981-52fb90a005b4\n",
      "2025-08-07 14:25:39,702 - INFO - Request ID is 615085a6-a8b7-4bd8-8981-52fb90a005b4\n",
      "2025-08-07 14:25:40,254 INFO status has been updated to accepted\n",
      "2025-08-07 14:25:40,254 - INFO - status has been updated to accepted\n",
      "2025-08-07 14:25:50,480 INFO status has been updated to running\n",
      "2025-08-07 14:25:50,480 - INFO - status has been updated to running\n",
      "2025-08-07 14:25:56,095 INFO status has been updated to successful\n",
      "2025-08-07 14:25:56,095 - INFO - status has been updated to successful\n",
      "2025-08-07 14:25:57,201 - INFO - Downloading https://object-store.os-api.cci2.ecmwf.int:443/cci2-prod-cache-3/2025-08-07/c6e34e4ad10036b0dce8f7d070cb307c.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3e569686884c2a820b25ba1df0729c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c6e34e4ad10036b0dce8f7d070cb307c.zip:   0%|          | 0.00/12.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 14:26:03,232 - INFO - ✅ 临时文件已成功下载到: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data/raw/era5/2025-07-18/temp_download\n",
      "2025-08-07 14:26:03,234 - INFO - 检测到下载文件为 ZIP 压缩包，开始解压...\n",
      "2025-08-07 14:26:03,260 - INFO - 已解压出 NetCDF 文件: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data/raw/era5/2025-07-18/data_stream-oper_stepType-instant.nc\n",
      "2025-08-07 14:26:03,261 - INFO - 已将文件重命名为: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data/raw/era5/2025-07-18/era5_data.nc\n",
      "2025-08-07 14:26:03,262 - INFO - 正在为 era5_data.nc 生成分析报告...\n",
      "2025-08-07 14:26:03,543 - INFO - ✅ 分析报告已成功保存到: /Users/zhangchao/Documents/Code/github/chromasky-toolkit/src/data/raw/era5/2025-07-18/era5_data.md\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 定义本次运行的目标日期 ---\n",
    "# (这个变量定义可以保留在之前的单元格，这里重申以保证逻辑完整)\n",
    "target_date_obj = datetime.strptime(TARGET_DATE_STR, \"%Y-%m-%d\").date()\n",
    "\n",
    "# --- 2. 检查文件是否存在 & 执行下载 ---\n",
    "logger.info(f\"===== 开始处理本地日期: {target_date_obj} =====\")\n",
    "expected_file_path = config.ERA5_DATA_DIR / target_date_obj.strftime('%Y-%m-%d') / \"era5_data.nc\"\n",
    "\n",
    "if expected_file_path.exists() and expected_file_path.stat().st_size < 1024:\n",
    "    logger.warning(f\"发现一个之前下载失败的小文件，正在删除: {expected_file_path}\")\n",
    "    expected_file_path.unlink()\n",
    "\n",
    "if expected_file_path.exists():\n",
    "    logger.info(f\"✅ NC 文件已存在，跳过下载: {expected_file_path}\")\n",
    "    downloaded_file_path = expected_file_path\n",
    "else:\n",
    "    logger.info(f\"NC 文件不存在，开始执行下载流程...\")\n",
    "    downloaded_file_path = download_era5_data(target_date_obj)\n",
    "\n",
    "# --- 3. 生成并保存分析报告 ---\n",
    "if downloaded_file_path and downloaded_file_path.exists():\n",
    "    \n",
    "    report_file_path = downloaded_file_path.with_suffix('.md')\n",
    "    \n",
    "    # 检查报告是否已存在，如果已存在则跳过分析\n",
    "    if report_file_path.exists():\n",
    "        logger.info(f\"✅ 分析报告已存在，跳过分析: {report_file_path}\")\n",
    "    else:\n",
    "        logger.info(f\"正在为 {downloaded_file_path.name} 生成分析报告...\")\n",
    "        try:\n",
    "            with xr.open_dataset(downloaded_file_path, engine=\"netcdf4\") as ds:\n",
    "                # 调用新函数生成报告内容\n",
    "                report_content = generate_analysis_report(ds)\n",
    "                \n",
    "                # 将报告内容写入文件\n",
    "                report_file_path.write_text(report_content, encoding='utf-8')\n",
    "                \n",
    "                logger.info(f\"✅ 分析报告已成功保存到: {report_file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ 分析或保存报告时发生错误: {e}\", exc_info=True)\n",
    "\n",
    "elif not downloaded_file_path:\n",
    "    logger.error(\"\\n😢 下载流程失败，无法生成分析报告。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromasky-toolkit (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
