{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26370f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 环境设置与导入完成。\n"
     ]
    }
   ],
   "source": [
    "# --- 核心库 ---\n",
    "import logging\n",
    "import json\n",
    "import cdsapi\n",
    "import zipfile\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from zoneinfo import ZoneInfo\n",
    "from typing import Tuple, Dict, List, Literal\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 项目模块 ---\n",
    "from chromasky_toolkit import config\n",
    "from chromasky_toolkit.map_drawer import generate_map_from_grid\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "# --- 日志设置 ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"CamsAodPipeline\")\n",
    "\n",
    "print(\"✅ 环境设置与导入完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c7d331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# --- 核心配置区：请在此处设置您的目标参数 ---\n",
    "# ======================================================================\n",
    "\n",
    "# 定义您想处理的未来事件意图列表。\n",
    "# 可用选项: 'today_sunrise', 'today_sunset', 'tomorrow_sunrise', 'tomorrow_sunset'\n",
    "TARGET_EVENT_INTENTIONS: List[Literal['today_sunrise', 'today_sunset', 'tomorrow_sunrise', 'tomorrow_sunset']] = [\n",
    "    # \"today_sunset\",\n",
    "    \"tomorrow_sunrise\",\n",
    "    # \"tomorrow_sunset\"\n",
    "]\n",
    "\n",
    "# (可选) 定义要可视化的 AOD 变量\n",
    "AOD_VAR_TO_VISUALIZE = 'aod550'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "791db995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_latest_available_cams_run() -> Tuple[datetime.date, str] | None:\n",
    "    \"\"\"\n",
    "    智能判断当前可用的最新 CAMS 运行周期 (00z 或 12z)。\n",
    "    CAMS 数据通常有较长的延迟，我们设置一个安全边际。\n",
    "    \"\"\"\n",
    "    logger.info(\"--- [CAMS] 正在寻找最新的可用运行周期... ---\")\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    safe_margin = timedelta(hours=9)\n",
    "    \n",
    "    potential_runs = [\n",
    "        (now_utc.date(), \"12:00\"),\n",
    "        (now_utc.date(), \"00:00\"),\n",
    "        (now_utc.date() - timedelta(days=1), \"12:00\"),\n",
    "        (now_utc.date() - timedelta(days=1), \"00:00\"),\n",
    "    ]\n",
    "\n",
    "    for run_date, run_hour_str in potential_runs:\n",
    "        run_time_utc = datetime.strptime(f\"{run_date.strftime('%Y-%m-%d')} {run_hour_str}\", \"%Y-%m-%d %H:%M\").replace(tzinfo=timezone.utc)\n",
    "        if (now_utc - run_time_utc) >= safe_margin:\n",
    "            logger.info(f\"✅ 找到最新的可用运行周期: {run_date.strftime('%Y-%m-%d')} {run_hour_str} UTC\")\n",
    "            return run_date, run_hour_str\n",
    "            \n",
    "    logger.error(\"❌ 在过去48小时内未能找到任何满足安全边际的 CAMS 运行周期。\")\n",
    "    return None\n",
    "\n",
    "def expand_target_events_for_cams(simple_events: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"将简单的事件意图展开为按天分组的具体事件列表。\"\"\"\n",
    "    expanded_by_day = {'today': [], 'tomorrow': []}\n",
    "    if 'today_sunrise' in simple_events:\n",
    "        expanded_by_day['today'].extend(config.SUNRISE_EVENT_TIMES)\n",
    "    if 'today_sunset' in simple_events:\n",
    "        expanded_by_day['today'].extend(config.SUNSET_EVENT_TIMES)\n",
    "    if 'tomorrow_sunrise' in simple_events:\n",
    "        expanded_by_day['tomorrow'].extend(config.SUNRISE_EVENT_TIMES)\n",
    "    if 'tomorrow_sunset' in simple_events:\n",
    "        expanded_by_day['tomorrow'].extend(config.SUNSET_EVENT_TIMES)\n",
    "    \n",
    "    expanded_by_day['today'] = sorted(list(set(expanded_by_day['today'])))\n",
    "    expanded_by_day['tomorrow'] = sorted(list(set(expanded_by_day['tomorrow'])))\n",
    "    return expanded_by_day\n",
    "\n",
    "def download_cams_aod_raw_data(run_date_obj: datetime.date, run_hour_str: str, events_to_process: List[str]) -> Path | None:\n",
    "    \"\"\"\n",
    "    为指定的 CAMS 运行周期下载包含所有预报时效的原始 AOD 数据。\n",
    "    如果数据已存在，则直接返回路径。\n",
    "    该版本会为所有指定意图的事件（无论是否已过去）计算预报时效。\n",
    "    \"\"\"\n",
    "    run_date_str = run_date_obj.strftime('%Y-%m-%d')\n",
    "    output_dir_name = f\"{run_date_obj.strftime('%Y%m%d')}_t{run_hour_str[:2]}z\"\n",
    "    output_dir = config.CAMS_AOD_DATA_DIR / output_dir_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    manifest_path = output_dir / \"manifest_aod.json\"\n",
    "    final_output_file = output_dir / \"aod_forecast.nc\"\n",
    "    temp_download_path = output_dir / \"temp_download\"\n",
    "\n",
    "    if manifest_path.exists() and final_output_file.exists():\n",
    "        logger.info(f\"✅ 原始 CAMS AOD 数据和清单文件已在 '{output_dir}' 存在，跳过下载。\")\n",
    "        return final_output_file\n",
    "        \n",
    "    logger.info(f\"--- [CAMS] 开始为运行周期 {run_date_str} {run_hour_str} UTC 下载新数据 ---\")\n",
    "    \n",
    "    # --- 动态计算需要的预报时效 ---\n",
    "    base_run_time = datetime.strptime(f\"{run_date_str} {run_hour_str}\", \"%Y-%m-%d %H:%M\").replace(tzinfo=timezone.utc)\n",
    "    local_tz = ZoneInfo(config.LOCAL_TZ)\n",
    "    today = datetime.now(local_tz).date()\n",
    "    tomorrow = today + timedelta(days=1)\n",
    "    \n",
    "    expanded_events_by_day = expand_target_events_for_cams(events_to_process)\n",
    "    \n",
    "    target_utc_times = []\n",
    "    # 移除 dt_local > now_local 的检查，确保所有意图都被处理\n",
    "    if expanded_events_by_day['today']:\n",
    "        for t_str in expanded_events_by_day['today']:\n",
    "            dt_local = datetime.combine(today, datetime.strptime(t_str, '%H:%M').time(), tzinfo=local_tz)\n",
    "            target_utc_times.append(dt_local.astimezone(timezone.utc))\n",
    "    if expanded_events_by_day['tomorrow']:\n",
    "        for t_str in expanded_events_by_day['tomorrow']:\n",
    "            dt_local = datetime.combine(tomorrow, datetime.strptime(t_str, '%H:%M').time(), tzinfo=local_tz)\n",
    "            target_utc_times.append(dt_local.astimezone(timezone.utc))\n",
    "\n",
    "    if not target_utc_times:\n",
    "        logger.warning(\"[CAMS] 根据您的配置，没有找到任何需要处理的事件。\")\n",
    "        return None\n",
    "\n",
    "    # 计算预报时效，并过滤掉负值\n",
    "    leadtime_hours_set = {round((t - base_run_time).total_seconds() / 3600) for t in target_utc_times}\n",
    "    leadtime_hours_set = {h for h in leadtime_hours_set if h >= 0}\n",
    "\n",
    "    if not leadtime_hours_set:\n",
    "        logger.warning(\"[CAMS] 计算出的所有目标事件都早于最新的预报运行周期，无法下载。\")\n",
    "        return None\n",
    "        \n",
    "    leadtime_hours_list = sorted([str(h) for h in leadtime_hours_set])\n",
    "    \n",
    "    logger.info(f\"将为 CAMS 运行周期下载 {len(leadtime_hours_list)} 个特定预报时效的数据: {leadtime_hours_list}\")\n",
    "\n",
    "    try:\n",
    "        c = cdsapi.Client(timeout=600, quiet=False, url=\"https://ads.atmosphere.copernicus.eu/api\", key=config.CDS_API_KEY)\n",
    "        area_bounds = [config.AREA_EXTRACTION[k] for k in [\"north\", \"west\", \"south\", \"east\"]]\n",
    "        \n",
    "        request_params = {\n",
    "            'date': run_date_str,\n",
    "            'time': run_hour_str,\n",
    "            'format': 'netcdf',\n",
    "            'variable': config.CAMS_AOD_VARIABLES,\n",
    "            'leadtime_hour': leadtime_hours_list,\n",
    "            'type': 'forecast',\n",
    "            'area': area_bounds\n",
    "        }\n",
    "\n",
    "        logger.info(\"正在向 Copernicus ADS 发送请求...\")\n",
    "        c.retrieve(config.CAMS_DATASET_NAME, request_params, str(temp_download_path))\n",
    "        logger.info(f\"✅ 临时文件已成功下载到: {temp_download_path}\")\n",
    "\n",
    "        if zipfile.is_zipfile(temp_download_path):\n",
    "            logger.info(\"检测到下载文件为 ZIP 压缩包，开始解压...\")\n",
    "            with zipfile.ZipFile(temp_download_path, 'r') as zip_ref:\n",
    "                nc_files_in_zip = [f for f in zip_ref.namelist() if f.endswith('.nc')]\n",
    "                if not nc_files_in_zip:\n",
    "                    raise FileNotFoundError(\"ZIP 包中未找到任何 .nc 文件！\")\n",
    "                source_nc_path_str = zip_ref.extract(nc_files_in_zip[0], path=output_dir)\n",
    "                Path(source_nc_path_str).rename(final_output_file)\n",
    "                logger.info(f\"已将文件重命名为: {final_output_file}\")\n",
    "        else:\n",
    "            logger.info(\"检测到下载文件为 NetCDF，直接重命名。\")\n",
    "            temp_download_path.rename(final_output_file)\n",
    "        \n",
    "        # 创建清单文件\n",
    "        forecast_details = []\n",
    "        for hour in sorted([int(h) for h in leadtime_hours_list]):\n",
    "            forecast_time_utc = base_run_time + timedelta(hours=hour)\n",
    "            forecast_time_local = forecast_time_utc.astimezone(local_tz)\n",
    "            forecast_details.append({\n",
    "                \"leadtime_hour\": hour,\n",
    "                \"forecast_time_utc\": forecast_time_utc.isoformat(),\n",
    "                \"forecast_time_local\": forecast_time_local.isoformat(),\n",
    "            })\n",
    "\n",
    "        manifest_content = {\n",
    "            \"base_run_time_utc\": base_run_time.isoformat(),\n",
    "            \"data_file_path\": str(final_output_file.relative_to(config.PROJECT_ROOT)),\n",
    "            \"forecasts\": forecast_details\n",
    "        }\n",
    "        \n",
    "        with open(manifest_path, 'w') as f:\n",
    "            json.dump(manifest_content, f, indent=4)\n",
    "        logger.info(f\"✅ AOD 数据清单已成功写入: {manifest_path}\")\n",
    "        return final_output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ 下载或处理 CAMS AOD 数据时发生严重错误: {e}\", exc_info=True)\n",
    "        return None\n",
    "    finally:\n",
    "        if temp_download_path.exists():\n",
    "            temp_download_path.unlink()\n",
    "            logger.info(f\"已清理临时文件: {temp_download_path}\")\n",
    "\n",
    "def download_and_process_cams_aod(run_date_obj: datetime.date, run_hour_str: str, events_to_process: List[str]) -> Dict[str, List[Path]]:\n",
    "    \"\"\"为指定的 CAMS 运行周期，下载原始 AOD 数据，并将其处理分解。\"\"\"\n",
    "    # 1. 下载原始 NetCDF 文件\n",
    "    raw_nc_path = download_cams_aod_raw_data(run_date_obj, run_hour_str, events_to_process)\n",
    "    \n",
    "    processed_files_by_event: Dict[str, List[Path]] = {}\n",
    "    \n",
    "    if not (raw_nc_path and raw_nc_path.exists()):\n",
    "        logger.error(\"❌ 原始 CAMS AOD 数据下载失败或未找到，无法进行处理。\")\n",
    "        return processed_files_by_event\n",
    "\n",
    "    # --- 2. 处理原始 NetCDF 文件 ---\n",
    "    logger.info(\"\\n\" + \"-\"*80)\n",
    "    logger.info(f\"--- 开始处理原始文件: {raw_nc_path.name} ---\")\n",
    "\n",
    "    try:\n",
    "        with xr.open_dataset(raw_nc_path, engine=\"netcdf4\") as ds:\n",
    "            manifest_path = raw_nc_path.with_name(\"manifest_aod.json\")\n",
    "            if not manifest_path.exists():\n",
    "                logger.error(f\"❌ 清单文件 {manifest_path} 未找到，无法确定要处理的时间点。\")\n",
    "                return processed_files_by_event\n",
    "\n",
    "            with open(manifest_path, 'r') as f:\n",
    "                manifest = json.load(f)\n",
    "            \n",
    "            for forecast_info in manifest.get('forecasts', []):\n",
    "                hour = forecast_info['leadtime_hour']\n",
    "                local_dt = datetime.fromisoformat(forecast_info['forecast_time_local'])\n",
    "                local_date_str = local_dt.strftime('%Y-%m-%d')\n",
    "                local_time_str_path = local_dt.strftime('%H%M')\n",
    "                \n",
    "                event_key = f\"{local_date_str}_{local_time_str_path}\"\n",
    "                processed_files_by_event[event_key] = []\n",
    "\n",
    "                target_forecast_period = timedelta(hours=hour)\n",
    "                time_slice = ds.sel(forecast_period=target_forecast_period, method='nearest').squeeze()\n",
    "\n",
    "                for var_name in config.CAMS_AOD_VARIABLES:\n",
    "                    if var_name in time_slice:\n",
    "                        data_slice = time_slice[var_name]\n",
    "                        \n",
    "                        output_dir = config.PROCESSED_DATA_DIR / \"future\" / local_date_str\n",
    "                        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        output_path = output_dir / f\"{var_name}_{local_time_str_path}.nc\"\n",
    "\n",
    "                        data_slice.attrs['original_utc_time'] = forecast_info['forecast_time_utc']\n",
    "                        data_slice.to_netcdf(output_path)\n",
    "                        \n",
    "                        logger.info(f\"  ✅ 已将 '{var_name}' @ {local_time_str_path} 保存到: {output_path.relative_to(config.PROJECT_ROOT)}\")\n",
    "                        processed_files_by_event[event_key].append(output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ 处理原始 CAMS AOD 文件时发生严重错误: {e}\", exc_info=True)\n",
    "\n",
    "    return processed_files_by_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4764a7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:43:34,946 - CamsAodPipeline - INFO - --- [CAMS] 正在寻找最新的可用运行周期... ---\n",
      "2025-08-10 22:43:34,947 - CamsAodPipeline - INFO - ✅ 找到最新的可用运行周期: 2025-08-10 00:00 UTC\n",
      "2025-08-10 22:43:34,947 - CamsAodPipeline - INFO - \n",
      "================================================================================\n",
      "2025-08-10 22:43:34,949 - CamsAodPipeline - INFO - ===== 开始为 2025-08-10 00:00z 运行周期的 CAMS 预报执行数据流水线 =====\n",
      "2025-08-10 22:43:34,950 - CamsAodPipeline - INFO - ✅ 原始 CAMS AOD 数据和清单文件已在 'C:\\Users\\zhang\\Documents\\Code\\chromasky-toolkit\\src\\data\\raw\\cams_aod\\20250810_t00z' 存在，跳过下载。\n",
      "2025-08-10 22:43:34,950 - CamsAodPipeline - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "2025-08-10 22:43:34,951 - CamsAodPipeline - INFO - --- 步骤二: 开始处理原始文件: aod_forecast.nc ---\n",
      "2025-08-10 22:43:34,960 - CamsAodPipeline - INFO - ✅ 所有数据处理完成，开始可视化...\n",
      "2025-08-10 22:43:34,961 - CamsAodPipeline - WARNING - 未能处理或生成任何文件，无法进行可视化。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【诊断】读取到的 manifest_aod.json 文件内容:\n",
      "{\n",
      "    \"base_run_time_utc\": \"2025-08-10T00:00:00+00:00\",\n",
      "    \"data_file_path\": \"data\\\\raw\\\\cams_aod\\\\20250810_t00z\\\\aod_forecast.nc\",\n",
      "    \"forecasts\": [\n",
      "        {\n",
      "            \"leadtime_hour\": 21,\n",
      "            \"forecast_time_utc\": \"2025-08-10T21:00:00+00:00\",\n",
      "            \"forecast_time_local\": \"2025-08-11T05:00:00+08:00\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "【诊断】从清单中提取到 1 个预报事件。\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 寻找最新的 CAMS 运行周期 ---\n",
    "cams_run_info = _find_latest_available_cams_run()\n",
    "\n",
    "if cams_run_info:\n",
    "    run_date, run_hour = cams_run_info\n",
    "    \n",
    "    # --- 2. 步骤一: 下载原始数据 ---\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(f\"===== 开始为 {run_date.strftime('%Y-%m-%d')} {run_hour}z 运行周期的 CAMS 预报执行数据流水线 =====\")\n",
    "    \n",
    "    raw_nc_path = download_cams_aod_raw_data(run_date, run_hour, TARGET_EVENT_INTENTIONS)\n",
    "\n",
    "    # --- 3. 步骤二: 处理原始数据并保存为独立文件 ---\n",
    "    if not (raw_nc_path and raw_nc_path.exists()):\n",
    "        logger.error(\"❌ 原始 CAMS AOD 数据下载失败或未找到，无法继续。\")\n",
    "    else:\n",
    "        logger.info(\"\\n\" + \"-\"*80)\n",
    "        logger.info(f\"--- 步骤二: 开始处理原始文件: {raw_nc_path.name} ---\")\n",
    "        \n",
    "        processed_files_by_event: Dict[str, List[Path]] = {}\n",
    "        try:\n",
    "            with xr.open_dataset(raw_nc_path, engine=\"netcdf4\") as ds:\n",
    "                manifest_path = raw_nc_path.with_name(\"manifest_aod.json\")\n",
    "                if not manifest_path.exists():\n",
    "                    logger.error(f\"❌ 清单文件 {manifest_path} 未找到，无法进行处理。\")\n",
    "                else:\n",
    "                    # ==========================================================\n",
    "                    # --- 核心调试：打印清单内容 ---\n",
    "                    # ==========================================================\n",
    "                    with open(manifest_path, 'r') as f:\n",
    "                        manifest_content_str = f.read()\n",
    "                        print(\"\\n【诊断】读取到的 manifest_aod.json 文件内容:\")\n",
    "                        print(manifest_content_str)\n",
    "                        # 重新解析\n",
    "                        manifest = json.loads(manifest_content_str)\n",
    "                    # ==========================================================\n",
    "\n",
    "                    forecast_list = manifest.get('forecasts', [])\n",
    "                    print(f\"【诊断】从清单中提取到 {len(forecast_list)} 个预报事件。\")\n",
    "                    \n",
    "                    for forecast_info in forecast_list:\n",
    "                        hour = forecast_info['leadtime_hour']\n",
    "                        local_dt = datetime.fromisoformat(forecast_info['forecast_time_local'])\n",
    "                        local_date_str = local_dt.strftime('%Y-%m-%d')\n",
    "                        local_time_str_path = local_dt.strftime('%H%M')\n",
    "                        event_key = f\"{local_date_str}_{local_time_str_path}\"\n",
    "                        \n",
    "                        target_forecast_period = timedelta(hours=hour)\n",
    "                        time_slice = ds.sel(forecast_period=target_forecast_period, method='nearest').squeeze()\n",
    "\n",
    "                        for var_name in config.CAMS_AOD_VARIABLES:\n",
    "                            if var_name in time_slice:\n",
    "                                data_slice = time_slice[var_name]\n",
    "                                output_dir = config.PROCESSED_DATA_DIR / \"future\" / local_date_str\n",
    "                                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                                output_path = output_dir / f\"{var_name}_{local_time_str_path}.nc\"\n",
    "                                data_slice.attrs['original_utc_time'] = forecast_info['forecast_time_utc']\n",
    "                                data_slice.to_netcdf(output_path)\n",
    "                                \n",
    "                                processed_files_by_event.setdefault(event_key, []).append(output_path)\n",
    "                                logger.info(f\"  ✅ 已保存: {output_path.relative_to(config.PROJECT_ROOT)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ 处理原始 CAMS AOD 文件时发生严重错误: {e}\", exc_info=True)\n",
    "\n",
    "        # --- 4. 步骤三: 可视化 ---\n",
    "\n",
    "        logger.info(\"✅ 所有数据处理完成，开始可视化...\")\n",
    "        \n",
    "        if not processed_files_by_event:\n",
    "            logger.warning(\"未能处理或生成任何文件，无法进行可视化。\")\n",
    "        else:\n",
    "            for event_key, nc_files in sorted(processed_files_by_event.items()):\n",
    "                if not nc_files: continue\n",
    "\n",
    "                local_date, local_time = event_key.split('_')\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(f\"--- 可视化事件 @ 本地时间: {local_date} {local_time[:2]}:{local_time[2:]} ---\")\n",
    "                \n",
    "                # 我们只可视化用户指定的那个变量\n",
    "                target_file = next((p for p in nc_files if p.name.startswith(AOD_VAR_TO_VISUALIZE)), None)\n",
    "\n",
    "                if not target_file:\n",
    "                    print(f\"  - 未能找到变量 '{AOD_VAR_TO_VISUALIZE}' 的已处理文件。\")\n",
    "                    continue\n",
    "\n",
    "                data_slice = xr.open_dataarray(target_file)\n",
    "                utc_time_obj = datetime.fromisoformat(data_slice.attrs['original_utc_time'])\n",
    "                \n",
    "                map_title = (\n",
    "                    f\"{data_slice.attrs.get('long_name', data_slice.name)}\\n\"\n",
    "                    f\"Forecast: {local_date} {local_time[:2]}:{local_time[2:]} (Local)\"\n",
    "                )\n",
    "                \n",
    "                image_bytes = generate_map_from_grid(data_slice, map_title)\n",
    "                if image_bytes:\n",
    "                    display(Image(data=image_bytes, width=700))\n",
    "\n",
    "else:\n",
    "    logger.error(\"❌ 未能找到可用的 CAMS 运行周期，任务无法执行。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
