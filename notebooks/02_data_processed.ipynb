{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f6fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config: 数据目录为 C:\\Users\\zhang\\Documents\\Code\\chromasky-toolkit\\map_data\n",
      "✅ 环境设置完毕。\n"
     ]
    }
   ],
   "source": [
    "# 核心库\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from chromasky_toolkit import config\n",
    "\n",
    "print(\"✅ 环境设置完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8afd965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在分析文件: era5_data.nc ---\n",
      "\n",
      "【可用的 UTC 日期】:\n",
      "- 2025-07-03\n",
      "- 2025-07-04\n",
      "\n",
      "【可用的 UTC 时间 (小时:分钟)】:\n",
      "- 00:00  10:00  11:00  12:00  13:00  20:00\n",
      "- 21:00  22:00  23:00\n",
      "\n",
      "【可用的图层 (变量)】:\n",
      "- hcc        (High cloud cover)\n",
      "- mcc        (Medium cloud cover)\n",
      "- lcc        (Low cloud cover)\n",
      "- tcc        (Total cloud cover)\n",
      "- sp         (Surface pressure)\n",
      "- t2m        (2 metre temperature)\n",
      "- d2m        (2 metre dewpoint temperature)\n"
     ]
    }
   ],
   "source": [
    "def analyze_nc_file(file_path: Path):\n",
    "    \"\"\"\n",
    "    分析指定的 NetCDF 文件，并打印出可供分离的参数。\n",
    "    \"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"❌ 文件不存在: {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- 正在分析文件: {file_path.name} ---\")\n",
    "    with xr.open_dataset(file_path, engine=\"netcdf4\") as ds:\n",
    "        # 1. 提取可用的 UTC 日期\n",
    "        # 假设时间坐标名为 'valid_time' 或 'time'\n",
    "        time_coord_name = 'valid_time' if 'valid_time' in ds.coords else 'time'\n",
    "        if time_coord_name in ds.coords:\n",
    "            unique_dates = pd.to_datetime(ds[time_coord_name].values).strftime('%Y-%m-%d').unique().tolist()\n",
    "            print(\"\\n【可用的 UTC 日期】:\")\n",
    "            for d in unique_dates:\n",
    "                print(f\"- {d}\")\n",
    "\n",
    "            # 2. 提取可用的 UTC 时间\n",
    "            unique_times = pd.to_datetime(ds[time_coord_name].values).strftime('%H:%M').unique().tolist()\n",
    "            print(\"\\n【可用的 UTC 时间 (小时:分钟)】:\")\n",
    "            # 每行打印 6 个，方便查看\n",
    "            for i in range(0, len(unique_times), 6):\n",
    "                print(\"- \" + \"  \".join(unique_times[i:i+6]))\n",
    "        else:\n",
    "            print(\"未找到有效的时间坐标 ('valid_time' 或 'time')。\")\n",
    "\n",
    "        # 3. 提取可用的图层 (数据变量)\n",
    "        print(\"\\n【可用的图层 (变量)】:\")\n",
    "        for var_name in ds.data_vars:\n",
    "            print(f\"- {var_name:<10} ({ds[var_name].attrs.get('long_name', 'N/A')})\")\n",
    "\n",
    "# --- 执行分析 ---\n",
    "TARGET_DATE_STR = \"2025-07-04\"\n",
    "target_date_obj = pd.to_datetime(TARGET_DATE_STR).date()\n",
    "raw_data_path = config.ERA5_DATA_DIR / target_date_obj.strftime('%Y-%m-%d') / \"era5_data.nc\"\n",
    "\n",
    "analyze_nc_file(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d92690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据切片已成功保存到: C:\\Users\\zhang\\Documents\\Code\\chromasky-toolkit\\data\\processed\\2025-07-04\\hcc_2100.nc\n"
     ]
    }
   ],
   "source": [
    "def extract_and_save_slice(source_nc_path: Path, utc_date: str, utc_time: str, variable: str) -> Path | None:\n",
    "    \"\"\"\n",
    "    从大的 NetCDF 文件中提取一个数据切片并保存。\n",
    "    \"\"\"\n",
    "    if not source_nc_path.exists():\n",
    "        print(f\"❌ 源文件不存在: {source_nc_path}\")\n",
    "        return None\n",
    "\n",
    "    with xr.open_dataset(source_nc_path, engine=\"netcdf4\") as ds:\n",
    "        try:\n",
    "            # 构建目标时间点\n",
    "            target_datetime = f\"{utc_date}T{utc_time}\"\n",
    "            \n",
    "            # 使用 .sel() 选择最接近该时间点的数据\n",
    "            time_coord_name = 'valid_time' if 'valid_time' in ds.coords else 'time'\n",
    "            data_slice = ds[variable].sel({time_coord_name: target_datetime}, method='nearest')\n",
    "            \n",
    "            # 构建分组的输出路径\n",
    "            time_str_for_path = utc_time.replace(':', '')\n",
    "            output_dir = config.PROCESSED_DATA_DIR / utc_date\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            output_path = output_dir / f\"{variable}_{time_str_for_path}.nc\"\n",
    "            \n",
    "            # 保存为新的 NetCDF 文件\n",
    "            data_slice.to_netcdf(output_path)\n",
    "            print(f\"✅ 数据切片已成功保存到: {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f\"❌ 错误: 变量 '{variable}' 或时间坐标 '{time_coord_name}' 在数据集中不存在。\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 提取或保存时发生错误: {e}\")\n",
    "        \n",
    "    return None\n",
    "\n",
    "# --- 执行分离 ---\n",
    "# 根据上一步的分析结果，手动选择你想要分离的参数\n",
    "target_utc_date = \"2025-07-04\"\n",
    "target_utc_time = \"21:00\"  # 例如选择 UTC 12:00 (对应北京时间晚上8点)\n",
    "target_variable = \"hcc\"    # 例如选择高云量 (High cloud cover)\n",
    "\n",
    "# 确保原始数据文件存在\n",
    "if raw_data_path.exists():\n",
    "    saved_slice_path = extract_and_save_slice(raw_data_path, target_utc_date, target_utc_time, target_variable)\n",
    "else:\n",
    "    print(f\"原始数据文件 {raw_data_path} 不存在，无法执行分离。\")\n",
    "    saved_slice_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68794882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 18:33:46,687 - MapDrawer - WARNING - 未检测到主流中文字体，中文可能无法正常显示。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在为 'High cloud cover on 2025-07-04 at 21:00 UTC' 生成暗色主题地图... ---\n",
      "✅ 暗色主题地图已成功保存到: C:\\Users\\zhang\\Documents\\Code\\chromasky-toolkit\\data\\processed\\2025-07-04\\hcc_2100.png\n"
     ]
    }
   ],
   "source": [
    "# --- 导入我们重构好的绘图函数 ---\n",
    "from chromasky_toolkit.map_drawer import generate_map_from_grid\n",
    "from IPython.display import display, Image # 确保 Image 已导入\n",
    "\n",
    "# --- 执行可视化 ---\n",
    "if 'saved_slice_path' in locals() and saved_slice_path and saved_slice_path.exists():\n",
    "    # 加载分离出来的数据\n",
    "    data_slice = xr.open_dataarray(saved_slice_path)\n",
    "    \n",
    "    # 创建一个描述性的标题\n",
    "    map_title = f\"{data_slice.attrs.get('long_name', data_slice.name)} on {target_utc_date} at {target_utc_time} UTC\"\n",
    "    \n",
    "    # 定义地图图片的输出路径\n",
    "    map_output_path = saved_slice_path.with_suffix('.png')\n",
    "    \n",
    "    # 调用绘图函数\n",
    "    generate_map_from_grid(data_slice, map_title, map_output_path)\n",
    "else:\n",
    "    print(\"⚠️ 未找到已分离的数据文件，无法进行可视化。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
